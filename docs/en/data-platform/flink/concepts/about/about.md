*Cloud Flink* is a service for stream processing and transferring any volume of data from sources to target systems. The service is developed based on [Apache Flink](https://flink.apache.org/) and Kubernetes.

The Apache Flink service operates on the concept of distributed stream computing: data is considered as a continuous stream that is processed in parallel and distributed. This approach allows achieving high performance and scalability.

Cloud Flink automates the following processes:

- Stream event processing.
- Large datasets processing.
- Data aggregation and analysis.
- Transferring data to various systems (e.g. transferring data from Kafka to a database, from a database to a data storage).
- ETL tasks processing: processes of extraction (Extract), transformation (Transform) and loading data (Load).

Possible scenarios for using the service:

- Financial analytics: transaction tracking, fraud detection.
- Website monitoring: real-time user activity analysis.
- Analysis of data from devices: processing primary data obtained from various sensors and devices.
- Machine learning: training and evaluating machine learning models.
- Big Data analytics: processing big data to identify trends, forecasts, etc.

You can manage the Cloud Flink resources through your VK Cloud management console and work with Flink clusters through the [Flink CLI](https://docs.kafka-ui.provectus.io/overview/readme).

To get started with the Cloud Flink service, [leave a request](https://cloud.vk.com/flink/).
