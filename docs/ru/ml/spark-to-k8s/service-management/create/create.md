<tabs>
<tablist>
<tab>Личный кабинет</tab>
</tablist>
<tabpanel>

1. [Перейдите](https://msk.cloud.vk.com/app/) в личный кабинет VK Cloud.
1. Выберите проект, где нужно создать кластер.
1. Перейдите в раздел **ML Platform → Spark в k8s**.
1. Перейдите на вкладку **Кластеры**.
1. Нажмите кнопку **Добавить кластер** или **Добавить**.
1. На шаге «Создание кластера»:

   1. Задайте общие настройки:

      - **Имя кластера**: может содержать только латинские буквы, цифры и спецсимволы `.`, `-`, `_`.

      - **Зона доступности**: [зона доступности](/ru/intro/start/architecture#az) для кластера.

      - **Сеть**: сеть и подсеть, в которых будут размещаться узлы кластера. Если нужных сети и подсети нет в списке, [создайте](/ru/networks/vnet/service-management/net) их.

   1. Задайте настройки worker-узлов в блоке **Настройки worker-нод**:

      - **Категория виртуальной машины**: выберите категорию предустановленных конфигураций ВМ. Подробнее в [обзоре сервиса Cloud Servers](/ru/computing/iaas/concepts/about#shablony_konfiguraciy).

      - **Тип виртуальной машины:** [шаблон конфигурации](/ru/computing/iaas/concepts/about#shablony_konfiguraciy) для worker-узлов.

        Шаблоны с высокопроизводительными CPU доступны [по запросу в службу поддержки](/ru/contacts). Чтобы воспользоваться этими шаблонами, выберите опцию **Показывать только высокопроизводительные CPU**.

      - **Включить автомасштабирование**: выберите эту опцию, чтобы кластер автоматически масштабировал количество worker-узлов в зависимости от нагрузки.

        Затем задайте минимальное и максимальное количество узлов, в пределах которого допустимо масштабирование. Допустимый диапазон значений: от 1 до 100.

        По умолчанию опция выключена. Кластер с выключенным автомасштабированием будет содержать один worker-узел.

   1. Задайте дополнительные настройки:

      - **Выбор registry**: реестр Docker, образы из которого будут использоваться при запуске заданий Spark.

        Если нужного реестра нет в списке:

        1. Выберите пункт **Создать новый registry**.

           Реестр будет размещен на выделенной виртуальной машине, которая не входит в состав кластера и тарифицируется отдельно.

        1. Укажите реквизиты для доступа к реестру:

           - **Имя пользователя registry**: может содержать только латинские буквы, цифры и спецсимволы `.`, `-`, `_`.
           - **Пароль пользователя registry**: можно придумать пароль или сгенерировать его.

             <warn>

             Сохраните пароль. При утере его невозможно восстановить.

             </warn>

             Требования к паролю:
             
             - допустимо использовать только заглавные и строчные латинские буквы, цифры, спецсимволы `!`, `#`, `$`, `%`, `&`, `(`, `)`, `*`, `+`, `,`, `.`, `:`, `;`, `<`, `=`, `>`, `?`, `@`, `[`, `]`, `^`, `_`, `{`, `|`, `}`, `~`, `-`, `` ` ``, `;`.
             - пароль должен содержать хотя бы одну букву латинского алфавита и хотя бы одну цифру.

      - **Ключ виртуальной машины**: ключ, который используется для [подключения к узлам кластера по SSH](/ru/computing/iaas/service-management/vm/vm-connect/vm-connect-nix). Выберите существующий ключ или создайте новый.

        <warn>

        Если выбрать пункт **Без ключа**, то подключение по SSH будет невозможно.

        </warn>

      - **Режим работы кластера**: определяет конфигурацию master-узла.

        - **DEV**: для master-узла будет использоваться виртуальная машина с 2 vCPU и 4 GB RAM.
        - **PROD**: для master-узла будет использоваться виртуальная машина с 6 vCPU и 6 GB RAM.

   1. Выберите опции, влияющие на жизненный цикл неактивного кластера.

      Если в кластере нет запущенных заданий Spark, он становится неактивным. Перечисленные ниже опции определяют жизненный цикл именно такого кластера. Кластер возвращается в активное состояние при запуске нового задания Spark.

      Доступные опции:

      - **Уничтожение после неактивности**: когда заданное время истечет, неактивный кластер будет автоматически удален.

        По умолчанию опция выключена, и кластер существует, пока не будет удален вручную. Опция полезна в кластерах, используемых для разовых задач.

      - **Переход кластера в спящий режим**: когда заданное время истечет, неактивный кластер перейдет в спящий режим. В этом режиме тарифицируются только диски узлов кластера, вычислительные ресурсы не тарифицируются.

        Кластер будет выведен из спящего режима, когда будет запущено новое задание Spark.

        По умолчанию опция выключена, и кластер работает, пока не будет удален, даже если в нем нет запущенных заданий Spark. Опция полезна, чтобы сэкономить вычислительные ресурсы при длительных перерывах между запусками заданий Spark.

      <details>
      <summary>Примеры влияния опций на жизненный цикл кластера</summary>

      - Пусть настроено только время неактивности до уничтожения (120 минут, 2 часа).

        Тогда, если кластер неактивен с 13:00, то в 15:00 он будет удален.

      - Пусть настроено только время до перехода в спящий режим (120 минут, 2 часа).

        Тогда, если кластер неактивен с 13:00, то в 15:00 он перейдет в спящий режим.

      - Пусть настроено время до перехода в спящий режим (60 минут, 1 час) и время неактивности до уничтожения (120 минут, 2 часа).

        Тогда, если кластер неактивен с 13:00, то в 14:00 он перейдет в спящий режим, а в 15:00 будет удален.

      - Пусть настроено время до перехода в спящий режим (120 минут, 2 часа) и время неактивности до уничтожения (60 минут, 1 час).

        Тогда, если кластер неактивен с 13:00, то в 14:00 он будет удален.

      </details>

   1. Определите режим работы кластера с помощью опции **Private mode**:

      - Eсли опция отключена, каждому инстансу кластера задаются внешние IP-адреса и DNS-имена. Все инстансы кластера, включая Spark History Server и Docker Registry доступны из интернета.
      - Eсли опция включена, кластер будет создан без внешних IP-адресов и DNS-имен. В этом режиме доступ к Spark History Server и Docker Registry, а также доступ к кластеру по API возможен только из локальной сети или через VPN.

   1. Нажмите кнопку **Следующий шаг**.

1. На шаге «Настройки Spark»:

   1. (Опционально) Задайте продвинутые настройки Spark. Эти настройки будут использоваться всеми заданиями Spark, которые будут запускаться в кластере.

      Можно настроить:

      - **Spark configuration**: перечень свойств (properties), отвечающих за [конфигурацию Spark](https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/docs/user-guide.md#specifying-spark-configuration).
      - **Переменные окружения**: перечень переменных среды окружения (environment variables) для Spark.

      Каждое свойство или переменная должны размещаться на отдельной строке в следующем формате:

      ```text
      <имя свойства или переменной>: <значение>
      ```

      Описания свойств должны быть корректны с точки зрения [синтаксиса YAML](https://yaml.org/spec/).

      <details>
      <summary>Примеры описаний свойств и переменных</summary>

      - Перечень из нескольких свойств Spark:

        ```yaml
        spark.eventLog.dir: s3a://spark-bucket
        spark.eventLog.enabled: "true"
        spark.hadoop.fs.s3a.endpoint: https://hb.bizmrg.com
        spark.hadoop.fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
        ```

      - Перечень из нескольких переменных среды окружения:

        ```shell
        ENV_VAR_1: env_var_1_value
        ENV_VAR_2: env_var_2_value
        ENV_VAR_3: env_var_3_value
        ```

      </details>

   1. Нажмите кнопку **Создать кластер**.

      Дождитесь завершения операции. Создание кластера может занять длительное время.

</tabpanel>
</tabs>
