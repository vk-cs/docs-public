При развертывании нескольких нод, запускаются одинаковые инстансы одного сервиса (или приложения), для балансировки нагрузки или высокой доступности. Вероятно вы не захотите, чтобы все ноды были развернуты на одну физическую машину. Однако, если у вас есть кластер, в котором ноды играют одну роль (например, сервер приложений), а другие ноды играют другую роль (например, база данных), вы можете разместить эти ноды на одной физической машине, чтобы связь между нодами была быстрее.

Чтобы удовлетворить эти требования к совместному размещению нод внутри кластера, у вас есть несколько вариантов, описанных ниже.

## Использование группы серверов в профиле

Чтобы управлять привязкой узлов кластера, вы можете создать группу серверов, вызвав командную строку nova:

```
​​$ openstack server group create sg01 --policy affinity
```

Отобразиться:

```
+--------------+------+------------+---------+---------------+---------+----------+
| Id           | Name | Project Id | User Id | Policies      | Members | Metadata |
+--------------+------+------------+---------+---------------+---------+----------+
| 54a88567-... | sg01 | ...        | ...     | [u'affinity'] | []      | {}       |
+--------------+------+------------+---------+---------------+---------+----------+
```

После того как вы создали профиль сервера nova, вы можете ввести имя группы серверов в свойстве _scheduler_hints_:

```
cat web_cluster.yaml
```

Отобразиться:

```
type: os.nova.server
version: 1.0
properties:
  name: web_server

  <... other properties go here ...>

  scheduler_hints:
    group: sg01
```

Когда вы создадите кластер с использованием этого профиля, ноды сервера будут загружены на один и тот же физический хост. Другими словами, привязка управляется непосредственно службой nova compute. Если нет физических узлов, удовлетворяющих ограничениям, запросы на создание узлов завершатся неудачей.

Позже, когда вы создадите кластер с использованием этого профиля, серверные ноды будут загружаться на том же физическом хосте, если это возможно. Другими словами, affinity управляется напрямую сервисом вычислений nova. Если нет физических хостов, удовлетворяющих ограничениям, запросы на создание ноды завершатся ошибкой.

## Используйте тот же или другой хост в профиле

При добавлении узлов в существующий кластер, новые ноды могут ссылаться на другой объект профиля того же типа профиля (т.е. os.nova.server). Если ожидается, что новая нода будет запущена на том же или другом хосте из набора серверных нод, вы также можете указать ограничение, как scheduler_hints.

Например, у вас есть два серверных узла в кластере с идентификаторами UUID “UUID1" и "UUID2" соответственно, вы можете ввести ограничения планирования в профиле, как показано ниже:

```
cat standalone_server.yaml
```

Отобразиться:

```
type: os.nova.server
version: 1.0
properties:
  name: web_server

  <... other properties go here ...>

  scheduler_hints:
    different_host:
      - UUID1
      - UUID2
```

При добавлении ноды, использующего этот профиль, в кластер создание ноды либо завершается неудачно (например, не найден доступный хост), либо нода успешно создается на другом хосте, отличном от указанных узлов сервера.

Аналогично, вы можете заменить ключ different_host выше на same_host, чтобы указать, что новая нода совмещена с указанными существующими узлами.

## Управление Affinity с помощью политики Affinity

Еще одним вариантом управлением привязкой узлов является использование [политики affinity](https://docs.openstack.org/senlin/pike/user/policy_types/affinity.html).
Создавая и прикрепляя политику affinity к кластеру, вы все равно можете контролировать распределение узлов относительно базовых узлов.
