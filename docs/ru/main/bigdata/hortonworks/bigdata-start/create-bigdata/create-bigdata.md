## Создание кластера

Создание кластера Big Data производится в веб-интерфейсе панели управления VK Cloud.

В личном кабинете панели управления VK Cloud во вкладке "Большие данные" находится меню для создания кластера Big Data.

![](./assets/1601643470213.1-png)

Далее, нажав кнопку "Добавить кластер" откроется меню с выбором необходимой конфигурации и версии:

![](./assets/1601646274414.2-png)

*Airflow* \- это набор библиотек для запуска и мониторинга задач, записанных на Python. Уже настроен на запуск задач на рабочих узлах, необходимо только самостоятельно разложить код задач по узлам. В качестве компонента может быть установлен на кластерах Hadoop и Spark.

*DataFlow-HDF-v34 -*шаблон основан на Hortonworks Data Flow. Данный кластер управляет потоками данных и производит потоковую аналитику. После первичной установки управление осуществляется также через консоль Ambari. Версии компонентов:

- Apache NiFi 1.9.0
- NiFi Registry 0.3.0
- Apache MiNiFi Java Agent 0.6.0
- Apache MiNiFi C++ 0.6.0
- Hortonworks Schema Registry 0.7.0
- Hortonworks Streaming Analytics Manager 0.6.0

*Spark -* набор для параллельной обработки больших данных в памяти. Шаблон ориентирован на быструю обработку данных в приближенном к реальному времени режиме.

*Spark-HDP-v31* - расширенный набор компонентов. Дополнительно доступны Spark, Livy2, HBase, Oozie, Sqoop, Jupyter.

На следующем этапе создания кластера следует ввести описание кластера:

![](./assets/1601646393598.6-png)

*Имя кластера* - имя может содержать только буквы латинского алфавита в нижнем регистре, цифры или знаки "." и "-". Кириллицу и другие символы использовать не получится.

*Зона доступности* - выбор зоны доступности (рекомендуем DP1 или MS1)

*Ключевая пара* - можно выбрать ключевую пару из выпадающего списка или создать новую в разделе "Вычислительные ресурсы" - "Ключевые пары".

*Сеть* - Выбор сети для создания кластера.

**Внимание**

Создание кластера в сети ext-net (с внешним IP-адресом) сейчас невозможно. Стоит использовать приватную сеть или floating-IP. При использовании приватной сети стоит убедиться, что выбранная приватная сеть содержит хотя бы один маршрутизатор.

Далее также указать параметры узлов - head и worker:

![](./assets/1601646586298.7-png)

После заполнения полей и нажатия кнопки "Далее" появляется информационное окно о времени создания кластера и доступе к интерфейсу Ambari.

![](./assets/1601647566872.8-png)

Первичная инициализация кластера и установка компонентов Hadoop занимает 25-30 минут.

Примерно через 5-8 минут после начала запуска появится возможность доступа в интерфейс Ambari и отслеживания хода процесса установки.

## Подключение к кластеру

К кластерам Hadoop и Spark возможен доступ по SSH для запуска задач, установки дополнительных компонентов.
