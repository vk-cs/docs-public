Загрузка файлов размером более 100 МБ через AWS CLI происходит со скоростью значительно ниже пропускной способности интернет-канала.

При передаче файлов по одному TCP-соединению проблема может возникать из-за высокой задержки сети (latency). Чтобы максимально использовать пропускную способность интернет-канала, загружайте файл одновременно в несколько потоков. Для этого используйте [составную загрузку](/ru/storage/s3/concepts/features#object_uploading) и выберите наиболее подходящие для вашей ситуации количество одновременно загружаемых частей файла и их размер:

- Увеличение размера каждой части уменьшает общее количество API-запросов и служебный трафик, что сокращает общий объем трафика.
- Увеличение количества частей, которые будут загружаться параллельно, сокращает общее время загрузки файла. Однако этот подход ограничен мощностью вашего процессора и пропускной способностью интернет-канала.

### Решение

1. Убедитесь, что для загрузки объектов в бакет через AWS CLI используется команда `aws s3 cp`, а не `aws s3api put-object`. Команда `aws s3 cp` автоматически использует составную загрузку для объектов, размер которых превышает значение параметра `multipart_threshold` (по умолчанию 8 МБ).

1. Оптимизируйте параметры составной загрузки:

   ```console
   aws configure set default.s3.<ИМЯ_ПАРАМЕТРА> <ЗНАЧЕНИЕ>
   ```

   Здесь:

   - `<ИМЯ_ПАРАМЕТРА>` — имя параметра составной загрузки:
      - `multipart_threshold`: минимальный размер файла, необходимый для составной загрузки (по умолчанию 8 МБ).
      - `multipart_chunksize`: размер частей файла при составной загрузке (по умолчанию 8 МБ).
      - `max_concurrent_requests`: количество частей файла, которые будут загружаться параллельно (по умолчанию 10).
   - `<ЗНАЧЕНИЕ>` — новое значение параметра составной загрузки.

   {cut(Примеры команд)}

   ```console
   aws configure set default.s3.multipart_chunksize 16MB
   ```
   
   ```console
   aws configure set default.s3.max_concurrent_requests 20
   ```

   {/cut}

   {note:warn}
   Максимальное количество частей объекта — 10000. При выборе значения параметра `multipart_chunksize` убедитесь, что для самого большого файла общее количество частей не превысит это ограничение.
   {/note}