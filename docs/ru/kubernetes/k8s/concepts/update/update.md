Для кластеров Kubernetes в VK Cloud доступна операция обновления версии Kubernetes на одну из [поддерживаемых версий](../versions/version-support). Понижать версии нельзя.

При обновлении кластера также обновляется часть [компонентов](../versions/components) кластера. Причем если обновляемый вместе с кластером компонент был удален, он восстановится при обновлении кластера. Перечень обновляемых компонентов:

- Gatekeeper.
- Shell Operator.
- CoreDNS.

  При обновлении CoreDNS текущий [Corefile](https://coredns.io/2017/07/23/corefile-explained/) перезаписывается на новый с настройками по умолчанию.

  Если в кластере используется модифицированный Corefile, создайте его резервную копию перед обновлением кластера.

Аддоны не обновляются вместе с кластером. При необходимости [обновите аддоны самостоятельно](../../instructions/addons/manage-addons#obnovlenie_versii_addona) после завершения обновления кластера.

Процедура обновления отличается для кластеров версий 1.16 и ниже. Обновить их можно только путем переноса резервной копии данных в новый кластер нужной версии, например, с помощью [Velero](https://velero.io/docs).

## {heading(Процедуры обновления master- и worker-узлов)[id=update-process]}

Обновление кластера происходит следующим образом:

1. Обновляются master-узлы. Обновление происходит по принципу rolling update (шаг за шагом):

   1. Обновляется первый master-узел: он выводится из кластера, обновляется, проходит проверку успешности обновления и возвращается обратно в кластер.
   1. Как только в кластер вернулся обновленный master-узел, обновляется следующий узел. Последовательно, по одному узлу за шаг, обновляются все master-узлы кластера.

   Чтобы обеспечить бесперебойную работу сервисов на время обновления кластера, рекомендуется создавать кластеры, в которых 3–5 master-узлов.

1. Обновляются worker-узлы в группах.

   Процедура тоже выполняется по принципу rolling update, но за шаг обновляется не один, а максимально возможное количество узлов. Это количество рассчитывается, исходя из [настройки группы узлов](/ru/kubernetes/k8s/instructions/helpers/node-group-settings) **Процент недоступных нод при обновлении кластера**. Значение этой настройки вы можете установить как в момент [создания](/ru/kubernetes/k8s/instructions/manage-node-group#add_group) группы узлов, так и перед началом [обновления](/ru/kubernetes/k8s/instructions/manage-node-group#configure_node_update) кластера. При расчетах используется округление до целого в большую сторону.

## {heading(Как посчитать процент недоступных узлов при обновлении кластера)[id=unavailable-nodes]}

Во время обновления узлы становятся недоступными, и Cloud Containers автоматически перераспределяет нагрузку с них на свободные узлы. При обновлении кластера функция автоматического масштабирования не работает, поэтому необходимо иметь достаточное количество запасных master- и worker-узлов для переноса нагрузки с обновляемых.

При выборе значения для настройки **Процент недоступных нод при обновлении кластера** учтите не только желаемое количество одновременно обновляемых узлов, но и доступные ресурсы кластера, так как в процессе обновления нагрузка с обновляемых узлов должна быть перенаправлена на запасные узлы. Иначе для приложений, расположенных на обновляемых узлах, не будет доступных ресурсов. Также обеспечьте достаточный запас узлов на случай возникновения дополнительной нагрузки на те узлы, которые продолжат работать над нагрузкой, перенесенной с обновляемых узлов. Обычно это значение устанавливается на уровне 1% от общего количества узлов.

Таким образом, если в кластере из 30 узлов вы планируете одновременное обновление 10 из них и выставляете соответствующее значение настройки **Процент недоступных нод при обновлении кластера**, у вас должно быть как минимум 10 резервных узлов, на которые будет перенесена нагрузка с обновляемых. Также необходимо иметь один дополнительный узел на случай, если нагрузка возрастет.

Рассмотрим пример, как рассчитать значение настройки **Процент недоступных нод при обновлении кластера**. Предположим, что:

- В кластере есть группа из девяти worker-узлов, на которых выполняется критичная для бизнеса нагрузка. Эти сервисы и приложения должны быть доступны в течение всего процесса обновления.
- Для работы нагрузки требуется не менее шести узлов, т.е. можно позволить одновременное обновление трех узлов.

Чтобы выбрать значение настройки **Процент недоступных нод при обновлении кластера**:

1. Вычислите, какой процент узлов допустимо обновлять. Для этого разделите максимальное число узлов, которое допустимо обновлять, на общее число узлов, и умножьте на 100:

   `(3 / 9) x 100 = 33,33333...%`

1. Округлите полученный результат в меньшую сторону. Это и будет оптимальное значение настройки:
   
   `9 x 33% = 2,97`

   Полученный дробный результат будет округлен до целого в большую сторону. Итого можно одновременно обновлять три узла из девяти, что удовлетворяет требованиям.

1. Убедитесь, что у вас в запасе есть достаточное количество узлов, чтобы Cloud Containers мог перенести на них нагрузку с обновляемых узлов. Если worker-узлов недостаточно, [добавьте](/ru/kubernetes/k8s/instructions/manage-node-group#add_group) их. 

1. Задайте значение настройки:

   - либо строго равное вычисленному проценту, чтобы обновлялось максимально допустимое количество узлов;
   - либо меньше вычисленного процента, чтобы обновлялось меньшее количество узлов.

В приведенном примере:

- при значении настройки в 33% узлы будут обновляться по 3 штуки за раз;
- при значении настройки в 20% узлы будут обновляться по 2 штуки за раз;
- при значении настройки в 10% узлы будут обновляться по 1 штуке за раз.
