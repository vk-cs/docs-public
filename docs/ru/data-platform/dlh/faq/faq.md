{cut(Какие инструменты использовать для сбора данных?)}

Выбор инструментов зависит от выбранной [модели получения данных](/ru/data-platform/dlh/concepts/architecture#data_processing_models).

[cols="1,1", options="header"]
|===
|Модель
|Инструменты

|PULL-модель
|[Cloud Airflow](../concepts/components/airflow), [Cloud Spark](../concepts/components/spark) (пакетная обработка), [Cloud Trino](../concepts/components/trino)

|PUSH-модель
|[Cloud Spark](../concepts/components/spark) (потоковая обработка)

|===

{/cut}

{cut(Какие преимущества и недостатки у PULL-модели?)}

Основное преимущество получения данных по PULL-модели — запрос данных происходит по требованию, когда они действительно нужны.

Недостатки:

- Задержка доставки данных в хранилище, так как данные обновляются только по расписанию или вручную.
- Риск перегрузить источник, так как постоянные запросы данных могут замедлять работу системы.

Подробнее об особенностях PULL-модели в [статье по архитектуре DLH](/ru/data-platform/dlh/concepts/architecture#data_processing_models).

{/cut}

{cut(Какие преимущества и недостатки у PUSH-модели?)}

Основное преимущество получения данных по PUSH-модели в том, что не нужно запрашивать данные, они поступают без задержек в режиме реального времени.

Основной недостаток — необходимость разработки компонента для отправки данных (Producer API) при подключении нового источника данных к хранилищу. Это увеличивает затраты на интеграцию.

Подробнее об особенностях PUSH-модели в [статье по архитектуре DLH](/ru/data-platform/dlh/concepts/architecture#data_processing_models).

{/cut}

{cut(В чем основное отличие между Cloud Spark и Cloud Trino?)}

Основное отличие заключается в их назначении и способе обработки данных.

[cols="1,1,1", options="header"]
|===
|Критерий
|Cloud Spark
|Cloud Trino

|Mодель обработки данных
|PULL-модель (пакетная обработка), PUSH-модель (потоковая обработка, микробатчи)
|PULL-модель

|Ресурсоемкость
|Требует долгоживущих кластеров
|Временное выделение ресурсов — рабочие узлы (Workers) автоматически удаляются после завершения обработки

|Работа с данными
|Может изменять данные
|Не модифицирует исходные данные

|Задачи
|Применяется для сложных ETL- и ELT-процессов
|Специализируется на оптимизации и выполнении SQL-запросов

|Основное назначение
|Машинное обучение
|Интерактивная аналитика

|===

В Data Lakehouse компоненты [Cloud Spark](../concepts/components/spark) и [Cloud Trino](../concepts/components/trino) дополняют друг друга: Spark готовит данные, Trino обеспечивает быстрый доступ к ним.

{/cut}
