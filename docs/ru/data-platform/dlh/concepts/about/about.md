Data Lakehouse (DLH) — это гибридная архитектура управления данными, которую можно организовать на платформе VK Cloud. Она объединяет масштабируемость и гибкость [Data Lake](../compare/data-lake) с надежностью и структурированностью [Data Warehouse](../compare/dwh), обеспечивая единое пространство для хранения, обработки и анализа данных любого объема и формата с поддержкой ACID-транзакций, версионного контроля и совместимостью с современными аналитическими инструментами (Spark, Trino, BI-системами).

Архитектура сервиса позволяет упростить хранение «сырых» неструктурированных данных, сделать инфраструктуру для них дешевле и при этом эффективно выполнять аналитические SQL-запросы без потери качества результатов. Таким образом, сервис сочетает в себе преимущества Data Lake и Data Warehouse.

В Data Lakehouse слой хранения данных реализован на базе хранилища S3, а для доступа к данным используется привычный SQL-интерфейс. Физически оба слоя разнесены и могут горизонтально масштабироваться независимо друг от друга.

Неструктурированные данные сохраняются в хранилище S3 из различных источников в форматах данных: TSV, CSV, XML, syslog, JSON и т.д. Например, такими данными могут быть:

- видеозаписи с камер наружного наблюдения;
- телеметрия с датчиков и устройств;
- графические файлы;
- данные о поведении пользователей сайтов;
- логи из информационных систем.

В «сыром» виде такие данные непригодны для ежедневной аналитики в BI-системах, но могут быть использованы для быстрой отработки новых бизнес-гипотез с помощью алгоритмов машинного обучения или других методов Data Science.

Чтобы организовать полноценный доступ аналитических сервисов к данным Data Lakehouse, необходимо разметить и каталогизировать информацию об объектах в S3-хранилище в одном из общепринятых открытых форматов (например, с помощью сервиса [Cloud Iceberg Metastore](/ru/data-platform/dlh/concepts/components/iceberg)). Затем к размеченным данным через API-интерфейс подключается движок выполнения SQL-запросов на базе [Cloud Trino](/ru/data-platform/dlh/concepts/components/trino) или [Cloud Spark](/ru/data-platform/dlh/concepts/components/spark), чтобы организовать сквозную потоковую передачу событий в реальном времени.

Таким образом, DLH позволяет использовать инструменты бизнес-аналитики непосредственно в исходных данных, повышая их актуальность, а также уменьшая задержку и затраты, связанные с необходимостью выполнения ETL-операций.

## Когда внедряют VK Data Lakehouse?

Data Lakehouse от VK Cloud является эффективным решением, если нужно:

- заменить устаревший Hadoop-стек работы с данными;
- переехать из Greenplum;
- внедрить систему работы с большими данными на базе существующего S3;
- построить Data Office «с нуля».

## Как перенести данные в VK Data Lakehouse?

VK Cloud предлагает два варианта переноса данных:

- **Интеграция** — временное подключение к данным по запросу. При каждом обращении информация передается между системами.
- **Миграция** — однократное перемещение данных с их полным переносом в новую систему.

Подробнее о том, как перенести данные в Data Lakehouse от VK Cloud, на [официальном сайте](https://cloud.vk.com/vk-data-lakehouse/).
